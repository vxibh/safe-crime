{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e77389-55b0-452f-8938-5ddc357ed40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_emails(directory, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Process text files, eml files, or files without an extension\n",
    "                if file.endswith('.txt') or file.endswith('.eml') or not os.path.splitext(file)[1]:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                            content = f.read()\n",
    "                            out_file.write(content + '\\n\\n')  # Separate emails by two newlines\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Paths to directories\n",
    "ham_dir = 'enron/ham'\n",
    "spam_dir = 'enron/spam'\n",
    "\n",
    "# Output files\n",
    "ham_output_file = 'enron/ham.txt'\n",
    "spam_output_file = 'enron/spam.txt'\n",
    "\n",
    "# Extract emails\n",
    "extract_emails(ham_dir, ham_output_file)\n",
    "extract_emails(spam_dir, spam_output_file)\n",
    "\n",
    "print(\"Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37114fdc-01f2-4e19-9cb0-ce66c1248ac8",
   "metadata": {},
   "source": [
    "## #1 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc58eb5-bbf3-45e7-8056-05bf266c62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset from disk...\n",
      "Iter:0 Loss:0.1418565838862508\n",
      "Iter:1 Loss:0.1159124479776207\n",
      "Iter:2 Loss:0.11007672910511375\n",
      "Iter:3 Loss:0.10665691746145255\n",
      "Iter:4 Loss:0.10412171061464175\n",
      "Iter:5 Loss:0.10202175002694532\n",
      "Iter:6 Loss:0.10078361353158154\n",
      "Iter:7 Loss:0.09973163654990577\n",
      "Iter:8 Loss:0.09914064915691775\n",
      "Iter:9 Loss:0.09824559484017459\n",
      "Iter:10 Loss:0.09769536162716529\n",
      "Iter:11 Loss:0.09697567747573058\n",
      "Iter:12 Loss:0.09684459533264063\n",
      "Iter:13 Loss:0.09674045756105\n",
      "Iter:14 Loss:0.09605884690921715\n",
      "Iter:15 Loss:0.09590132617151204\n",
      "Iter:16 Loss:0.09578045455963016\n",
      "Iter:17 Loss:0.09500135219551235\n",
      "Iter:18 Loss:0.09517674220316232\n",
      "Iter:19 Loss:0.09461852895063669\n",
      " I:2000 % Correct:99.497\n",
      " Accuracy: %99.4\n",
      "False Positives: %0.89    <- privacy violation level\n",
      "False Negatives: %0.30   <- security risk level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import chardet\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "print(\"Importing dataset from disk...\")\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "# Detect encoding for spam.txt\n",
    "encoding_spam = detect_encoding('spam.txt')\n",
    "with open('spam.txt', 'r', encoding=encoding_spam, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "spam = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "# Detect encoding for ham.txt\n",
    "encoding_ham = detect_encoding('ham.txt')\n",
    "with open('ham.txt', 'r', encoding=encoding_ham, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "ham = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, positives, negatives, iterations=10, alpha=0.01, regularization_strength=0.01):\n",
    "        \n",
    "        self.maxweight = 10\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            for word in email:\n",
    "                cnts[word] += 1\n",
    "        \n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "        # Initialize weights\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "        \n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "    \n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        \n",
    "        for iter in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "\n",
    "            print(\"Iter:\" + str(iter) + \" Loss:\" + str(error / float(n)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        x = np.clip(x, -500, 500)  # Clip values to avoid overflow\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def predict(self, email):\n",
    "        return self.unencrypted_predict(email)\n",
    "    \n",
    "    def unencrypted_predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            pred += self.weights[self.word2index[word]]\n",
    "        pred = self.softmax(pred)\n",
    "        return pred\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email)\n",
    "        delta = (pred - target)\n",
    "        for word in email:\n",
    "            self.weights[self.word2index[word]] -= (delta * self.alpha + self.regularization_strength * self.weights[self.word2index[word]])\n",
    "        return delta\n",
    "\n",
    "model = LogisticRegression(spam[0:-1000], ham[0:-1000], iterations=20, alpha=0.01, regularization_strength=0.005)\n",
    "\n",
    "# Evaluate the model\n",
    "fp = 0\n",
    "tn = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, h in enumerate(ham[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred < 0.5:\n",
    "        tn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * tn / float(tn + fp))[0:6])\n",
    "\n",
    "for i, h in enumerate(spam[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred > 0.5:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "print(\"\\n Accuracy: %\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "print(\"False Positives: %\" + str(100 * fp / float(tp + fp))[0:4] + \"    <- privacy violation level\")\n",
    "print(\"False Negatives: %\" + str(100 * fn / float(tn + fn))[0:4] + \"   <- security risk level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069383a7-ff88-4e9e-88b4-fd2686c6830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from flask import Flask, request, jsonify\n",
    "import re\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Assuming `model` is your unencrypted model from previous steps\n",
    "# Initialize the model here if necessary\n",
    "\n",
    "# Define the preprocessing function to handle case and punctuation\n",
    "def preprocess_email(email):\n",
    "    # Convert to lowercase\n",
    "    email = email.lower()\n",
    "    \n",
    "    # Remove punctuation using regex\n",
    "    email = re.sub(r'[^\\w\\s]', '', email)\n",
    "    \n",
    "    # Tokenize by splitting on spaces\n",
    "    email_tokens = email.split()\n",
    "    \n",
    "    return email_tokens\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    email = data.get('email', '')\n",
    "    \n",
    "    if not email:\n",
    "        return jsonify({'error': 'No email provided'}), 400\n",
    "    \n",
    "    # Preprocess the email input\n",
    "    email_tokens = preprocess_email(email)\n",
    "    \n",
    "    # Run through the model\n",
    "    try:\n",
    "        pred = model.predict(email_tokens)\n",
    "        \n",
    "        # Determine whether it's spam or not\n",
    "        if pred > 0.5:\n",
    "            result = \"spam\"\n",
    "        else:\n",
    "            result = \"not spam\"\n",
    "        \n",
    "        # Return the result as JSON\n",
    "        return jsonify({'prediction': result})\n",
    "    \n",
    "    except KeyError as e:\n",
    "        # Return an error message if a word is not found in the vocabulary\n",
    "        return jsonify({'error': f\"Word '{e.args[0]}' not in vocabulary\"}), 400\n",
    "\n",
    "# Run the Flask server\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=12345)  # Default port is 5000\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4478f4-2cd2-449b-bde0-dee5bf1bb494",
   "metadata": {},
   "source": [
    "## Pallier Homomorphic Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecd7267-c86e-4e28-bfe8-80eee0112d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original messages: 42, 23\n",
      "Encrypted messages: <EncryptedNumber object at 0x10f0df980>, <EncryptedNumber object at 0x10f261b50>\n",
      "Encrypted sum: <EncryptedNumber object at 0x10aefb620>\n",
      "Decrypted sum: 65\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import libnum\n",
    "\n",
    "# Function to compute modular inverse\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "# L function for decryption\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "# Paillier key generation using libnum for prime generation\n",
    "def generate_keys(bit_length=512):\n",
    "    # Generate two large prime numbers p and q using libnum\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "\n",
    "    n = p * q  # n = p * q\n",
    "    n_sq = n * n  # n^2 for the modulus in encryption\n",
    "\n",
    "    # λ (lambda) = lcm(p-1, q-1)\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "\n",
    "    # g can be any number (usually n+1)\n",
    "    g = n + 1\n",
    "\n",
    "    # µ = (L(g^λ mod n^2))^(-1) mod n\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "\n",
    "    return public_key, private_key\n",
    "\n",
    "# Custom EncryptedNumber class to mimic object-like string representation\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "    def __str__(self):\n",
    "        # This returns a string similar to an object representation\n",
    "        return f\"<EncryptedNumber object at {hex(id(self))}>\"\n",
    "\n",
    "# Paillier encryption\n",
    "def encrypt(public_key, plaintext):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Choose random r where 1 <= r < n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "\n",
    "    # Encryption formula: c = g^m * r^n mod n^2\n",
    "    ciphertext = (pow(g, plaintext, n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)  # Wrap ciphertext in EncryptedNumber class\n",
    "\n",
    "# Paillier decryption\n",
    "def decrypt(private_key, public_key, encrypted_number):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Extract the actual ciphertext from the EncryptedNumber object\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "\n",
    "    # Decryption formula: m = L(c^λ mod n^2) * µ mod n\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext\n",
    "\n",
    "# Homomorphic addition of two ciphertexts\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Homomorphic addition: c3 = (c1 * c2) mod n^2\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Key generation (512-bit security)\n",
    "    public_key, private_key = generate_keys(bit_length=512)\n",
    "\n",
    "    # Encrypt two messages\n",
    "    m1 = 42\n",
    "    m2 = 23\n",
    "    print(f\"Original messages: {m1}, {m2}\")\n",
    "\n",
    "    c1 = encrypt(public_key, m1)\n",
    "    c2 = encrypt(public_key, m2)\n",
    "    print(f\"Encrypted messages: {c1}, {c2}\")\n",
    "\n",
    "    # Homomorphic addition of encrypted messages\n",
    "    c3 = homomorphic_add(public_key, c1, c2)\n",
    "    print(f\"Encrypted sum: {c3}\")\n",
    "\n",
    "    # Decrypt the sum\n",
    "    decrypted_sum = decrypt(private_key, public_key, c3)\n",
    "    print(f\"Decrypted sum: {decrypted_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "552e58e3-e00c-442d-ba9c-9582385d7837",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6531ba1d-ba87-4db0-81d4-4cd158f5bfac",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import chardet\n",
    "import math\n",
    "import libnum\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Function to detect file encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "# Load datasets\n",
    "def load_data(file_path):\n",
    "    encoding = detect_encoding(file_path)\n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "        raw = f.readlines()\n",
    "    return [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "spam = load_data('spam.txt')\n",
    "ham = load_data('ham.txt')\n",
    "\n",
    "# Paillier Encryption Functions\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "def generate_keys(bit_length=512):\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "    n = p * q\n",
    "    n_sq = n * n\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "    g = n + 1\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "    return public_key, private_key\n",
    "\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "    def __str__(self):\n",
    "        return f\"<EncryptedNumber object at {hex(id(self))}>\"\n",
    "\n",
    "def encrypt(public_key, plaintext):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "    ciphertext = (pow(g, plaintext, n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)\n",
    "\n",
    "def decrypt(private_key, public_key, encrypted_number):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext\n",
    "\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "# Logistic Regression Class\n",
    "class LogisticRegression:\n",
    "    def __init__(self, positives, negatives, public_key, iterations=10, alpha=0.01, regularization_strength=0.01):\n",
    "        self.maxweight = 10\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.pubkey = public_key\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            for word in email:\n",
    "                cnts[word] += 1\n",
    "\n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # Initialize weights\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "        \n",
    "        # Scale and convert weights to native Python int\n",
    "        self.weights = np.round(self.weights * 100).astype(int).tolist()\n",
    "\n",
    "        # Encrypt the weights\n",
    "        self.encrypted_weights = [encrypt(public_key, weight) for weight in self.weights]\n",
    "\n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "\n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        for iter in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "            print(\"Iter:\" + str(iter) + \" Loss:\" + str(error / float(n)))\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, email):\n",
    "        return self.encrypted_predict(email)\n",
    "\n",
    "    def encrypted_predict(self, email):\n",
    "        pred = encrypt(self.pubkey, 0)  # Start with encrypted zero\n",
    "        for word in email:\n",
    "            weight = self.encrypted_weights[self.word2index[word]]\n",
    "            pred = homomorphic_add(self.pubkey, pred, weight)\n",
    "        return pred\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.decrypt_predict(email)\n",
    "        delta = (pred - target)\n",
    "        for word in email:\n",
    "            index = self.word2index[word]\n",
    "            self.weights[index] -= (delta * self.alpha + self.regularization_strength * self.weights[index])\n",
    "            self.encrypted_weights[index] = encrypt(self.pubkey, int(self.weights[index]))  # Ensure conversion\n",
    "        return delta\n",
    "\n",
    "    def decrypt_predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            pred += self.weights[self.word2index[word]]\n",
    "        pred = self.softmax(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate keys\n",
    "    public_key, private_key = generate_keys(bit_length=512)\n",
    "    \n",
    "    # Create and train Logistic Regression model\n",
    "    model = LogisticRegression(spam[0:-1000], ham[0:-1000], public_key, iterations=20, alpha=0.01, regularization_strength=0.005)\n",
    "\n",
    "    # Evaluate the model\n",
    "    fp, tn, tp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for i, h in enumerate(ham[-1000:]):\n",
    "        encrypted_pred = model.predict(h)\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred < 0.5:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for i, h in enumerate(spam[-1000:]):\n",
    "        encrypted_pred = model.predict(h)\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred > 0.5:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "    total = tn + tp + fp + fn\n",
    "    accuracy = 100 * (tn + tp) / total if total > 0 else 0\n",
    "    print(\"\\n Accuracy: %\" + str(accuracy)[0:6])\n",
    "    print(\"False Positives: %\" + str(100 * fp / float(tp + fp))[0:4] + \"    <- privacy violation level\")\n",
    "    print(\"False Negatives: %\" + str(100 * fn / float(tn + fn))[0:4] + \"   <- security risk level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "59b45486-035c-4e54-a15f-1ad55b8f3652",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting to load data...\n",
      "Detected encoding: Windows-1252\n",
      "Dataset imported.\n",
      "Starting to load data...\n",
      "Detected encoding: ascii\n",
      "Dataset imported.\n",
      "Epoch 1 started, weights encrypted.\n",
      "Iteration: 1, Loss: 0.0943, Max Weight: 0.8499133334729208\n",
      "Iteration: 2, Loss: 0.0512, Max Weight: 0.7720277889291725\n",
      "Iteration: 3, Loss: 0.0422, Max Weight: 0.7746412814448762\n",
      "Iteration: 4, Loss: 0.0372, Max Weight: 0.7745550268801938\n",
      "Iteration: 5, Loss: 0.0339, Max Weight: 0.7904771956373626\n",
      "Epoch 6 started, weights encrypted.\n",
      "Iteration: 6, Loss: 0.0315, Max Weight: 0.8219411712428307\n",
      "Iteration: 7, Loss: 0.0297, Max Weight: 0.87692066922867\n",
      "Iteration: 8, Loss: 0.0282, Max Weight: 0.9262058073962733\n",
      "Iteration: 9, Loss: 0.0270, Max Weight: 0.9707931348521376\n",
      "Iteration: 10, Loss: 0.0259, Max Weight: 1.0114150831017963\n",
      "\n",
      "Accuracy: 50.00%\n",
      "True Positives: 0, True Negatives: 1000, False Positives: 0, False Negatives: 1000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import math\n",
    "import re\n",
    "import libnum\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "# Function to detect file encoding\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "\n",
    "def clean_text(text):\n",
    "    # Remove HTML tags and entities like &nbsp;\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    # Remove email headers like 'Subject:'\n",
    "    text = re.sub(r'Subject:', '', text)\n",
    "    return text\n",
    "    \n",
    "def load_data(file_path):\n",
    "    print(\"Starting to load data...\")\n",
    "    encoding = detect_encoding(file_path)\n",
    "    print(f\"Detected encoding: {encoding}\")\n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "        raw = f.readlines()\n",
    "    \n",
    "    print(\"Dataset imported.\")\n",
    "    \n",
    "    # Clean each email and split into words\n",
    "    return [[word for word in clean_text(row).split() if word.strip()] for row in raw]\n",
    "\n",
    "\n",
    "# Importing dataset\n",
    "spam = load_data('spam.txt')\n",
    "ham = load_data('ham.txt')\n",
    "\n",
    "# Paillier Encryption Functions\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "def generate_keys(bit_length=256):\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "    n = p * q\n",
    "    n_sq = n * n\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "    g = n + 1\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "    return public_key, private_key\n",
    "\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "def encrypt(public_key, plaintext, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "    ciphertext = (pow(g, int(plaintext * scaling_factor), n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)\n",
    "\n",
    "def decrypt(private_key, public_key, encrypted_number, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext / scaling_factor\n",
    "\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "# Logistic Regression Class\n",
    "class LogisticRegression:\n",
    "    def __init__(self, positives, negatives, public_key, iterations=20, alpha=0.01, regularization_strength=0.005, weight_scale=1e5):\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.pubkey = public_key\n",
    "        self.weight_scale = weight_scale\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            cnts.update(email)\n",
    "\n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # Initialize weights with lower variance\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "\n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "\n",
    "    def train(self, positives, negatives, iterations=20):\n",
    "        for iter in range(iterations):\n",
    "            if iter % 5 == 0:  # Encrypt weights every 5 epochs\n",
    "                self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "                print(f\"Epoch {iter + 1} started, weights encrypted.\")\n",
    "\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "\n",
    "            max_weight = max(abs(w) for w in self.weights)\n",
    "            print(f\"Iteration: {iter + 1}, Loss: {error / float(n):.4f}, Max Weight: {max_weight}\")\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    # Modify the predict function to match unencrypted prediction first for comparison\n",
    "    def predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "        if word in self.word2index:\n",
    "            pred += self.weights[self.word2index[word]]\n",
    "        pred = self.softmax(pred)\n",
    "        return pred\n",
    "\n",
    "\n",
    "    def encrypted_predict(self, email):\n",
    "        pred = encrypt(self.pubkey, 0)  # Start with encrypted zero\n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                weight = self.encrypted_weights[self.word2index[word]]\n",
    "                pred = homomorphic_add(self.pubkey, pred, weight)\n",
    "        return pred\n",
    "\n",
    "    # Modify the learn function to use simple delta update as in target code\n",
    "    def learn(self, email, target):\n",
    "        pred = self.decrypt_predict(email)\n",
    "        delta = pred - target\n",
    "    \n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                self.weights[self.word2index[word]] -= delta * self.alpha\n",
    "        return delta\n",
    "\n",
    "\n",
    "    def decrypt_predict(self, email):\n",
    "        pred = sum(self.weights[self.word2index[word]] for word in email if word in self.word2index)\n",
    "        return self.softmax(pred)\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate keys\n",
    "    public_key, private_key = generate_keys(bit_length=64)  # Increased key size\n",
    "    \n",
    "    # Create and train Logistic Regression model\n",
    "    model = LogisticRegression(spam[0:-1000], ham[0:-1000], public_key, iterations=10, alpha=0.003)\n",
    "\n",
    "    # Evaluate the model\n",
    "    fp, tn, tp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for h in ham[-1000:]:\n",
    "        encrypted_pred = model.predict(h)\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred < 0.4:  # Increase threshold for TN\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for s in spam[-1000:]:\n",
    "        encrypted_pred = model.predict(s)\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred > 0.3:  # Increase threshold for TP\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "\n",
    "    total = tn + tp + fp + fn\n",
    "    accuracy = 100 * (tn + tp) / total if total > 0 else 0\n",
    "    print(f\"\\nAccuracy: {accuracy:.2f}%\")\n",
    "    print(f\"True Positives: {tp}, True Negatives: {tn}, False Positives: {fp}, False Negatives: {fn}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "dc916f9a-cd2a-46ad-8396-4a3c5f524308",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top words by weight: [('removed', np.float64(1.1705920727373356)), ('daren', np.float64(-1.1084337535007625)), ('thanks', np.float64(-1.0931768499059655)), ('attached', np.float64(-1.0820453731595625)), ('nbsp', np.float64(1.0766684057495002)), ('doc', np.float64(-1.0511789620975704)), ('neon', np.float64(-1.028657068918028)), ('money', np.float64(1.0245858763823161)), ('here', np.float64(0.9820507067122095)), ('2004', np.float64(0.9470461135994449))]\n"
     ]
    }
   ],
   "source": [
    "top_weights = sorted(zip(model.word2index.keys(), model.weights), key=lambda x: abs(x[1]), reverse=True)\n",
    "print(f\"Top words by weight: {top_weights[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9b19840d-970d-40e5-9b68-0126fc4ae4d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/6th1dqbx7j13bmbjw6wbpk440000gn/T/ipykernel_38738/513944821.py:114: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Loss: 0.0000\n",
      "Weights encrypted after training.\n",
      "Weights encrypted after training.\n",
      "False Positives: 0, True Negatives: 1000, True Positives: 989, False Negatives: 11\n",
      "\n",
      "Accuracy: 99.45%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import math\n",
    "import re\n",
    "import libnum\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    text = re.sub(r'Subject:', '', text)\n",
    "    return text\n",
    "    \n",
    "def load_data(file_path):\n",
    "    encoding = detect_encoding(file_path)\n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "        raw = f.readlines()\n",
    "    return [[word for word in clean_text(row).split() if word.strip()] for row in raw]\n",
    "\n",
    "spam = load_data('spam.txt')\n",
    "ham = load_data('ham.txt')\n",
    "\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "def generate_keys(bit_length=256):\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "    n = p * q\n",
    "    n_sq = n * n\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "    g = n + 1\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "    return public_key, private_key\n",
    "\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "def encrypt(public_key, plaintext, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "    ciphertext = (pow(g, int(plaintext * scaling_factor), n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)\n",
    "\n",
    "def decrypt(private_key, public_key, encrypted_number, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext / scaling_factor\n",
    "\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, positives, negatives, public_key, iterations=20, alpha=0.01, regularization_strength=0.001, weight_scale=1e5):\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.pubkey = public_key\n",
    "        self.weight_scale = weight_scale\n",
    "\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            cnts.update(email)\n",
    "\n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # Initialize weights as in target\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "\n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "        print(\"Weights encrypted after training.\")\n",
    "\n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        for iteration in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "        \n",
    "        print(f\"Iteration: {iteration + 1}, Loss: {error / n:.4f}\")\n",
    "    \n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "        print(\"Weights encrypted after training.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, email, encrypt_output=False):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                pred += self.weights[self.word2index[word]]\n",
    "    \n",
    "        pred = self.softmax(pred)\n",
    "    \n",
    "        if encrypt_output:\n",
    "            encrypted_pred = encrypt(self.pubkey, pred)\n",
    "            return encrypted_pred\n",
    "    \n",
    "        # Return classification (1 for spam, 0 for ham) based on a threshold\n",
    "        return 1 if pred >= 0.5 else 0  # Threshold is 0.5\n",
    "\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email)  # Unencrypted prediction\n",
    "        delta = pred - target  # This operation works because `pred` is unencrypted\n",
    "    \n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                self.weights[self.word2index[word]] -= self.alpha * delta\n",
    "\n",
    "        return delta\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    public_key, private_key = generate_keys(bit_length=64)\n",
    "    model = LogisticRegression(spam[0:-1000], ham[0:-1000], public_key, iterations=10, alpha=0.01)\n",
    "\n",
    "    fp, tn, tp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for h in ham[-1000:]:\n",
    "        encrypted_pred = model.predict(h, encrypt_output=True)  # Encrypt the output during prediction\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred <  0.5:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for s in spam[-1000:]:\n",
    "        encrypted_pred = model.predict(s, encrypt_output=True)  # Encrypt the output during prediction\n",
    "        pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred > 0.5:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "print(f\"False Positives: {fp}, True Negatives: {tn}, True Positives: {tp}, False Negatives: {fn}\")\n",
    "total = tn + tp + fp + fn\n",
    "accuracy = 100 * (tn + tp) / total if total > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d95fb13b-d488-4928-bf7e-a8c87a42bd71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(spam[57])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8e608c1-4aad-41c8-a6a3-6bf00dd25112",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.encrypted_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "bdb8663a-e2d8-4fac-bd47-02194fae3491",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/66/6th1dqbx7j13bmbjw6wbpk440000gn/T/ipykernel_38738/2907671338.py:114: RuntimeWarning: overflow encountered in exp\n",
      "  return 1 / (1 + np.exp(-x))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration: 10, Loss: 0.0000\n",
      "Weights encrypted after training.\n",
      "Weights encrypted after training.\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "can't multiply sequence by non-int of type 'EncryptedNumber'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[100], line 152\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m h \u001b[38;5;129;01min\u001b[39;00m ham[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1000\u001b[39m:]:\n\u001b[1;32m    151\u001b[0m     encrypted_pred \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(h, encrypt_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)  \u001b[38;5;66;03m# Encrypt the output during prediction\u001b[39;00m\n\u001b[0;32m--> 152\u001b[0m     pred \u001b[38;5;241m=\u001b[39m \u001b[43mencrypt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprivate_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpublic_key\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencrypted_pred\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m pred \u001b[38;5;241m<\u001b[39m  \u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m    154\u001b[0m         tn \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[0;32mIn[100], line 57\u001b[0m, in \u001b[0;36mencrypt\u001b[0;34m(public_key, plaintext, scaling_factor)\u001b[0m\n\u001b[1;32m     55\u001b[0m n_sq \u001b[38;5;241m=\u001b[39m n \u001b[38;5;241m*\u001b[39m n\n\u001b[1;32m     56\u001b[0m r \u001b[38;5;241m=\u001b[39m libnum\u001b[38;5;241m.\u001b[39mrandint_bits(n\u001b[38;5;241m.\u001b[39mbit_length() \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m%\u001b[39m n\n\u001b[0;32m---> 57\u001b[0m ciphertext \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mpow\u001b[39m(g, \u001b[38;5;28mint\u001b[39m(\u001b[43mplaintext\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mscaling_factor\u001b[49m), n_sq) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mpow\u001b[39m(r, n, n_sq)) \u001b[38;5;241m%\u001b[39m n_sq\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m EncryptedNumber(ciphertext)\n",
      "\u001b[0;31mTypeError\u001b[0m: can't multiply sequence by non-int of type 'EncryptedNumber'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import math\n",
    "import re\n",
    "import libnum\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    text = re.sub(r'Subject:', '', text)\n",
    "    return text\n",
    "    \n",
    "def load_data(file_path):\n",
    "    encoding = detect_encoding(file_path)\n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "        raw = f.readlines()\n",
    "    return [[word for word in clean_text(row).split() if word.strip()] for row in raw]\n",
    "\n",
    "spam = load_data('spam.txt')\n",
    "ham = load_data('ham.txt')\n",
    "\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "def generate_keys(bit_length=256):\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "    n = p * q\n",
    "    n_sq = n * n\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "    g = n + 1\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "    return public_key, private_key\n",
    "\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "def encrypt(public_key, plaintext, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "    ciphertext = (pow(g, int(plaintext * scaling_factor), n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)\n",
    "\n",
    "def decrypt(private_key, public_key, encrypted_number, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext / scaling_factor\n",
    "\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, positives, negatives, public_key, iterations=20, alpha=0.01, regularization_strength=0.001, weight_scale=1e5):\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.pubkey = public_key\n",
    "        self.weight_scale = weight_scale\n",
    "\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            cnts.update(email)\n",
    "\n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # Initialize weights as in target\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "\n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "        print(\"Weights encrypted after training.\")\n",
    "\n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        for iteration in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "        \n",
    "        print(f\"Iteration: {iteration + 1}, Loss: {error / n:.4f}\")\n",
    "    \n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "        print(\"Weights encrypted after training.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, email, encrypt_output=False):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                pred += self.weights[self.word2index[word]]\n",
    "    \n",
    "        pred = self.softmax(pred)\n",
    "    \n",
    "        if encrypt_output:\n",
    "            encrypted_pred = encrypt(self.pubkey, pred)\n",
    "            return encrypted_pred\n",
    "    \n",
    "        # Return classification (1 for spam, 0 for ham) based on a threshold\n",
    "        return 1 if pred >= 0.5 else 0  # Threshold is 0.5\n",
    "\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email)  # Unencrypted prediction\n",
    "        delta = pred - target  # This operation works because `pred` is unencrypted\n",
    "    \n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                self.weights[self.word2index[word]] -= self.alpha * delta\n",
    "\n",
    "        return delta\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    public_key, private_key = generate_keys(bit_length=64)\n",
    "    model = LogisticRegression(spam[0:-1000], ham[0:-1000], public_key, iterations=10, alpha=0.01)\n",
    "\n",
    "    fp, tn, tp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for h in ham[-1000:]:\n",
    "        encrypted_pred = model.predict(h, encrypt_output=True)  # Encrypt the output during prediction\n",
    "        pred = encrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred <  0.5:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for s in spam[-1000:]:\n",
    "        encrypted_pred = model.predict(s, encrypt_output=True)  # Encrypt the output during prediction\n",
    "        pred = encrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred > 0.5:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "print(f\"False Positives: {fp}, True Negatives: {tn}, True Positives: {tp}, False Negatives: {fn}\")\n",
    "total = tn + tp + fp + fn\n",
    "accuracy = 100 * (tn + tp) / total if total > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "6f4611da-0d41-4f7e-8d1a-e30b2c4f54c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detecting Encoding for spam.txt...\n",
      "Encoding detected: Windows-1252\n",
      "\n",
      "spam.txt  :  Windows-1252\n",
      "Dataset 'spam.txt' loaded successfully with 9000 records.\n",
      "\n",
      "Detecting Encoding for ham.txt...\n",
      "Encoding detected: ascii\n",
      "\n",
      "ham.txt  :  ascii\n",
      "Dataset 'ham.txt' loaded successfully with 22032 records.\n",
      "\n",
      "🔑 Generating keys, please wait...\n",
      "✓ Keys generated successfully! (bit length: 64)\n",
      "\n",
      "Initializing Logistic Regression model...\n",
      "Iteration: 1, Loss: 0.0517\n",
      "Iteration: 2, Loss: 0.0102\n",
      "Iteration: 3, Loss: 0.0033\n",
      "Iteration: 4, Loss: 0.0006\n",
      "Iteration: 5, Loss: 0.0005\n",
      "Iteration: 6, Loss: 0.0000\n",
      "Iteration: 7, Loss: 0.0000\n",
      "Iteration: 8, Loss: 0.0000\n",
      "Iteration: 9, Loss: 0.0000\n",
      "Iteration: 10, Loss: 0.0000\n",
      "Weights encrypted after training.\n",
      "False Positives: 0, True Negatives: 1000, True Positives: 1000, False Negatives: 0\n",
      "\n",
      "Accuracy: 100.00%\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import chardet\n",
    "import math\n",
    "import re\n",
    "import libnum\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "def clean_text(text):\n",
    "    text = re.sub(r'<[^>]+>', '', text)\n",
    "    text = re.sub(r'&\\w+;', '', text)\n",
    "    text = re.sub(r'Subject:', '', text)\n",
    "    return text\n",
    "    \n",
    "def load_data(file_path):\n",
    "    print(f\"Detecting Encoding for {file_path}...\")\n",
    "    encoding = detect_encoding(file_path)\n",
    "    print(f\"Encoding detected: {encoding}\\n\")\n",
    "\n",
    "    print(file_path, \" : \", encoding) \n",
    "    with open(file_path, 'r', encoding=encoding, errors='replace') as f:\n",
    "        raw = f.readlines()\n",
    "    print(f\"Dataset '{file_path}' loaded successfully with {len(raw)} records.\\n\")\n",
    "    return [[word for word in clean_text(row).split() if word.strip()] for row in raw]\n",
    "\n",
    "spam = load_data('spam.txt')\n",
    "ham = load_data('ham.txt')\n",
    "\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "def generate_keys(bit_length=256):\n",
    "    print(\"🔑 Generating keys, please wait...\")\n",
    "\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "    n = p * q\n",
    "    n_sq = n * n\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "    g = n + 1\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "    print(f\"✓ Keys generated successfully! (bit length: {bit_length})\\n\")\n",
    "\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "    return public_key, private_key\n",
    "\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "def encrypt(public_key, plaintext, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "    ciphertext = (pow(g, int(plaintext * scaling_factor), n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)\n",
    "\n",
    "def decrypt(private_key, public_key, encrypted_number, scaling_factor=10000):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext / scaling_factor\n",
    "\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "class LogisticRegression:\n",
    "    def __init__(self, positives, negatives, public_key, iterations=20, alpha=0.01, regularization_strength=0.001, weight_scale=1e5):\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        self.pubkey = public_key\n",
    "        self.weight_scale = weight_scale\n",
    "\n",
    "        print(f\"Initializing Logistic Regression model...\")\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            cnts.update(email)\n",
    "\n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "        # Initialize weights as in target\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "\n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "\n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        for iteration in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "        \n",
    "            print(f\"Iteration: {iteration + 1}, Loss: {error / n:.4f}\")\n",
    "    \n",
    "        # Encrypt weights after training\n",
    "        self.encrypted_weights = [encrypt(self.pubkey, int(weight)) for weight in self.weights]\n",
    "        print(\"Weights encrypted after training.\")\n",
    "\n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        x = np.clip(x, -500, 500)\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def predict(self, email, encrypt_output=True):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                pred += self.weights[self.word2index[word]]\n",
    "        \n",
    "        pred = self.softmax(pred)\n",
    "        \n",
    "        if encrypt_output:\n",
    "            encrypted_pred = encrypt(self.pubkey, pred)\n",
    "            return encrypted_pred\n",
    "        \n",
    "        # Return classification (1 for spam, 0 for ham) based on a threshold\n",
    "        return 1 if pred >= 0.5 else 0  # Threshold is 0.5\n",
    "\n",
    "\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email, encrypt_output=False)  # Unencrypted prediction\n",
    "        delta = pred - target  # This operation works because `pred` is unencrypted\n",
    "    \n",
    "        for word in email:\n",
    "            if word in self.word2index:\n",
    "                self.weights[self.word2index[word]] -= self.alpha * delta\n",
    "\n",
    "        return delta\n",
    "\n",
    "\n",
    "# Example Usage\n",
    "if __name__ == \"__main__\":\n",
    "    public_key, private_key = generate_keys(bit_length=64)\n",
    "    model = LogisticRegression(spam[0:-1000], ham[0:-1000], public_key, iterations=10, alpha=0.01)\n",
    "\n",
    "    fp, tn, tp, fn = 0, 0, 0, 0\n",
    "\n",
    "    for h in ham[-1000:]:\n",
    "        pred = model.predict(h, encrypt_output=False)  # Encrypt the output during prediction\n",
    "        #pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred <  0.5:\n",
    "            tn += 1\n",
    "        else:\n",
    "            fp += 1\n",
    "\n",
    "    for s in spam[-1000:]:\n",
    "        pred = model.predict(s, encrypt_output=False)  # Encrypt the output during prediction\n",
    "        #pred = decrypt(private_key, public_key, encrypted_pred)\n",
    "        if pred > 0.5:\n",
    "            tp += 1\n",
    "        else:\n",
    "            fn += 1\n",
    "\n",
    "print(f\"False Positives: {fp}, True Negatives: {tn}, True Positives: {tp}, False Negatives: {fn}\")\n",
    "total = tn + tp + fp + fn\n",
    "accuracy = 100 * (tn + tp) / total if total > 0 else 0\n",
    "print(f\"\\nAccuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "665ef89a-8cef-4f68-965c-4f5cd1da58a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<__main__.EncryptedNumber at 0x141aa5d00>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(spam[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11dccee-2442-4deb-93ab-83fd49ac613e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
