{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e77389-55b0-452f-8938-5ddc357ed40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The history saving thread hit an unexpected error (OperationalError('attempt to write a readonly database')).History will not be written to the database.\n",
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_emails(directory, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Process text files, eml files, or files without an extension\n",
    "                if file.endswith('.txt') or file.endswith('.eml') or not os.path.splitext(file)[1]:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                            content = f.read()\n",
    "                            out_file.write(content + '\\n\\n')  # Separate emails by two newlines\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Paths to directories\n",
    "ham_dir = 'enron/ham'\n",
    "spam_dir = 'enron/spam'\n",
    "\n",
    "# Output files\n",
    "ham_output_file = 'enron/ham.txt'\n",
    "spam_output_file = 'enron/spam.txt'\n",
    "\n",
    "# Extract emails\n",
    "extract_emails(ham_dir, ham_output_file)\n",
    "extract_emails(spam_dir, spam_output_file)\n",
    "\n",
    "print(\"Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37114fdc-01f2-4e19-9cb0-ce66c1248ac8",
   "metadata": {},
   "source": [
    "## #1 Logistic Regression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ebc58eb5-bbf3-45e7-8056-05bf266c62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset from disk...\n",
      "Iter:0 Loss:0.1418565838862508\n",
      "Iter:1 Loss:0.1159124479776207\n",
      "Iter:2 Loss:0.11007672910511375\n",
      "Iter:3 Loss:0.10665691746145255\n",
      "Iter:4 Loss:0.10412171061464175\n",
      "Iter:5 Loss:0.10202175002694532\n",
      "Iter:6 Loss:0.10078361353158154\n",
      "Iter:7 Loss:0.09973163654990577\n",
      "Iter:8 Loss:0.09914064915691775\n",
      "Iter:9 Loss:0.09824559484017459\n",
      "Iter:10 Loss:0.09769536162716529\n",
      "Iter:11 Loss:0.09697567747573058\n",
      "Iter:12 Loss:0.09684459533264063\n",
      "Iter:13 Loss:0.09674045756105\n",
      "Iter:14 Loss:0.09605884690921715\n",
      "Iter:15 Loss:0.09590132617151204\n",
      "Iter:16 Loss:0.09578045455963016\n",
      "Iter:17 Loss:0.09500135219551235\n",
      "Iter:18 Loss:0.09517674220316232\n",
      "Iter:19 Loss:0.09461852895063669\n",
      " I:2000 % Correct:99.497\n",
      " Accuracy: %99.4\n",
      "False Positives: %0.89    <- privacy violation level\n",
      "False Negatives: %0.30   <- security risk level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import chardet\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "print(\"Importing dataset from disk...\")\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "# Detect encoding for spam.txt\n",
    "encoding_spam = detect_encoding('spam.txt')\n",
    "with open('spam.txt', 'r', encoding=encoding_spam, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "spam = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "# Detect encoding for ham.txt\n",
    "encoding_ham = detect_encoding('ham.txt')\n",
    "with open('ham.txt', 'r', encoding=encoding_ham, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "ham = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, positives, negatives, iterations=10, alpha=0.01, regularization_strength=0.01):\n",
    "        \n",
    "        self.maxweight = 10\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            for word in email:\n",
    "                cnts[word] += 1\n",
    "        \n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "        # Initialize weights\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "        \n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "    \n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        \n",
    "        for iter in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "\n",
    "            print(\"Iter:\" + str(iter) + \" Loss:\" + str(error / float(n)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        x = np.clip(x, -500, 500)  # Clip values to avoid overflow\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def predict(self, email):\n",
    "        return self.unencrypted_predict(email)\n",
    "    \n",
    "    def unencrypted_predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            pred += self.weights[self.word2index[word]]\n",
    "        pred = self.softmax(pred)\n",
    "        return pred\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email)\n",
    "        delta = (pred - target)\n",
    "        for word in email:\n",
    "            self.weights[self.word2index[word]] -= (delta * self.alpha + self.regularization_strength * self.weights[self.word2index[word]])\n",
    "        return delta\n",
    "\n",
    "model = LogisticRegression(spam[0:-1000], ham[0:-1000], iterations=20, alpha=0.01, regularization_strength=0.005)\n",
    "\n",
    "# Evaluate the model\n",
    "fp = 0\n",
    "tn = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, h in enumerate(ham[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred < 0.5:\n",
    "        tn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * tn / float(tn + fp))[0:6])\n",
    "\n",
    "for i, h in enumerate(spam[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred > 0.5:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "print(\"\\n Accuracy: %\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "print(\"False Positives: %\" + str(100 * fp / float(tp + fp))[0:4] + \"    <- privacy violation level\")\n",
    "print(\"False Negatives: %\" + str(100 * fn / float(tn + fn))[0:4] + \"   <- security risk level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069383a7-ff88-4e9e-88b4-fd2686c6830c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## from flask import Flask, request, jsonify\n",
    "import re\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Assuming `model` is your unencrypted model from previous steps\n",
    "# Initialize the model here if necessary\n",
    "\n",
    "# Define the preprocessing function to handle case and punctuation\n",
    "def preprocess_email(email):\n",
    "    # Convert to lowercase\n",
    "    email = email.lower()\n",
    "    \n",
    "    # Remove punctuation using regex\n",
    "    email = re.sub(r'[^\\w\\s]', '', email)\n",
    "    \n",
    "    # Tokenize by splitting on spaces\n",
    "    email_tokens = email.split()\n",
    "    \n",
    "    return email_tokens\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    email = data.get('email', '')\n",
    "    \n",
    "    if not email:\n",
    "        return jsonify({'error': 'No email provided'}), 400\n",
    "    \n",
    "    # Preprocess the email input\n",
    "    email_tokens = preprocess_email(email)\n",
    "    \n",
    "    # Run through the model\n",
    "    try:\n",
    "        pred = model.predict(email_tokens)\n",
    "        \n",
    "        # Determine whether it's spam or not\n",
    "        if pred > 0.5:\n",
    "            result = \"spam\"\n",
    "        else:\n",
    "            result = \"not spam\"\n",
    "        \n",
    "        # Return the result as JSON\n",
    "        return jsonify({'prediction': result})\n",
    "    \n",
    "    except KeyError as e:\n",
    "        # Return an error message if a word is not found in the vocabulary\n",
    "        return jsonify({'error': f\"Word '{e.args[0]}' not in vocabulary\"}), 400\n",
    "\n",
    "# Run the Flask server\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=12345)  # Default port is 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c8b887e-4f96-4478-ad30-30851104e333",
   "metadata": {},
   "outputs": [],
   "source": [
    "import phe as paillier\n",
    "print (\"Generating paillier keypair\")\n",
    "pubkey, prikey = paillier.generate_paillier_keypair(n_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584fcec9-5bd7-4f56-b014-679a2852d25e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pubkey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m a \u001b[38;5;241m=\u001b[39m \u001b[43mpubkey\u001b[49m\u001b[38;5;241m.\u001b[39mencrypt (\u001b[38;5;241m123\u001b[39m)\n\u001b[1;32m      2\u001b[0m b\u001b[38;5;241m=\u001b[39m pubkey\u001b[38;5;241m.\u001b[39mencrypt (\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pubkey' is not defined"
     ]
    }
   ],
   "source": [
    "a = pubkey.encrypt (123)\n",
    "b= pubkey.encrypt (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba24d18-dd97-4494-8e74-4e10a2176fe6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prikey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprikey\u001b[49m\u001b[38;5;241m.\u001b[39mdecrypt(a)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prikey' is not defined"
     ]
    }
   ],
   "source": [
    "prikey.decrypt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769da172-c758-42d6-ae3f-b096ec58a055",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'a' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43ma\u001b[49m)\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(b)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'a' is not defined"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d89d6ff7-c033-414f-b6bc-f7fe1418d9ca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'prikey' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mprikey\u001b[49m\u001b[38;5;241m.\u001b[39mdecrypt(a\u001b[38;5;241m+\u001b[39ma)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'prikey' is not defined"
     ]
    }
   ],
   "source": [
    "prikey.decrypt(a+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d62489-f054-477d-8f3a-526bfba148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae67ec6-7680-4257-8de2-866efc84281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<phe.paillier.EncryptedNumber object at 0x10f307e60>\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9421577-655f-4174-b388-901001ca1bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prikey.decrypt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bba38b2-1a79-4994-bd59-19dafeffb2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da46b7b5-f1f6-45b1-ac67-c035e8fb10c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3d4478f4-2cd2-449b-bde0-dee5bf1bb494",
   "metadata": {},
   "source": [
    "## Pallier Homomorphic Encryption"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecd7267-c86e-4e28-bfe8-80eee0112d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original messages: 42, 23\n",
      "Encrypted messages: <EncryptedNumber object at 0x10f0df980>, <EncryptedNumber object at 0x10f261b50>\n",
      "Encrypted sum: <EncryptedNumber object at 0x10aefb620>\n",
      "Decrypted sum: 65\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import libnum\n",
    "\n",
    "# Function to compute modular inverse\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "# L function for decryption\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "# Paillier key generation using libnum for prime generation\n",
    "def generate_keys(bit_length=512):\n",
    "    # Generate two large prime numbers p and q using libnum\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "\n",
    "    n = p * q  # n = p * q\n",
    "    n_sq = n * n  # n^2 for the modulus in encryption\n",
    "\n",
    "    # λ (lambda) = lcm(p-1, q-1)\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "\n",
    "    # g can be any number (usually n+1)\n",
    "    g = n + 1\n",
    "\n",
    "    # µ = (L(g^λ mod n^2))^(-1) mod n\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "\n",
    "    return public_key, private_key\n",
    "\n",
    "# Custom EncryptedNumber class to mimic object-like string representation\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "    def __str__(self):\n",
    "        # This returns a string similar to an object representation\n",
    "        return f\"<EncryptedNumber object at {hex(id(self))}>\"\n",
    "\n",
    "# Paillier encryption\n",
    "def encrypt(public_key, plaintext):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Choose random r where 1 <= r < n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "\n",
    "    # Encryption formula: c = g^m * r^n mod n^2\n",
    "    ciphertext = (pow(g, plaintext, n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)  # Wrap ciphertext in EncryptedNumber class\n",
    "\n",
    "# Paillier decryption\n",
    "def decrypt(private_key, public_key, encrypted_number):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Extract the actual ciphertext from the EncryptedNumber object\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "\n",
    "    # Decryption formula: m = L(c^λ mod n^2) * µ mod n\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext\n",
    "\n",
    "# Homomorphic addition of two ciphertexts\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Homomorphic addition: c3 = (c1 * c2) mod n^2\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Key generation (512-bit security)\n",
    "    public_key, private_key = generate_keys(bit_length=512)\n",
    "\n",
    "    # Encrypt two messages\n",
    "    m1 = 42\n",
    "    m2 = 23\n",
    "    print(f\"Original messages: {m1}, {m2}\")\n",
    "\n",
    "    c1 = encrypt(public_key, m1)\n",
    "    c2 = encrypt(public_key, m2)\n",
    "    print(f\"Encrypted messages: {c1}, {c2}\")\n",
    "\n",
    "    # Homomorphic addition of encrypted messages\n",
    "    c3 = homomorphic_add(public_key, c1, c2)\n",
    "    print(f\"Encrypted sum: {c3}\")\n",
    "\n",
    "    # Decrypt the sum\n",
    "    decrypted_sum = decrypt(private_key, public_key, c3)\n",
    "    print(f\"Decrypted sum: {decrypted_sum}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14b5de0a-2363-4753-9c8a-16407a3bfa22",
   "metadata": {},
   "source": [
    "## SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38766db7-2121-4af7-a8d2-02eb836857a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset from disk...\n",
      "Iter:0 Avg Hinge Loss:0.33809849966091965\n",
      "Iter:1 Avg Hinge Loss:0.06428403878435547\n",
      "Iter:2 Avg Hinge Loss:0.05118881929946586\n",
      "Iter:3 Avg Hinge Loss:0.028179408464615925\n",
      "Iter:4 Avg Hinge Loss:0.06564766862604053\n",
      "Iter:5 Avg Hinge Loss:0.09000201096530512\n",
      "Iter:6 Avg Hinge Loss:0.003489506491584598\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import chardet\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "print(\"Importing dataset from disk...\")\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "# Detect encoding for spam.txt\n",
    "encoding_spam = detect_encoding('spam.txt')\n",
    "with open('spam.txt', 'r', encoding=encoding_spam, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "spam = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "# Detect encoding for ham.txt\n",
    "encoding_ham = detect_encoding('ham.txt')\n",
    "with open('ham.txt', 'r', encoding=encoding_ham, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "ham = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "class SVM:\n",
    "    \n",
    "    def __init__(self, positives, negatives, iterations=10, alpha=0.005, regularization_strength=0.05):\n",
    "        \n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            for word in email:\n",
    "                cnts[word] += 1\n",
    "        \n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "        # Initialize weights\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "        self.bias = 0  # SVM includes a bias term\n",
    "        \n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "    \n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        \n",
    "        for iter in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                # Train on positive and negative examples\n",
    "                error += self.learn(positives[i % len(positives)], 1)\n",
    "                error += self.learn(negatives[i % len(negatives)], -1)\n",
    "                n += 2\n",
    "\n",
    "            print(\"Iter:\" + str(iter) + \" Avg Hinge Loss:\" + str(error / float(n)))\n",
    "    \n",
    "    def predict(self, email):\n",
    "        pred = self.unencrypted_predict(email)\n",
    "        return np.sign(pred)  # SVM classifies based on the sign of the decision function\n",
    "    \n",
    "    def unencrypted_predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            if word in self.word2index:  # Avoid unseen words\n",
    "                pred += self.weights[self.word2index[word]]\n",
    "        pred += self.bias\n",
    "        return pred\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        \"\"\"\n",
    "        Learn from one example using hinge loss.\n",
    "        If the point is correctly classified and outside the margin, no weight update occurs.\n",
    "        \"\"\"\n",
    "        pred = self.unencrypted_predict(email)\n",
    "        if target * pred < 1:  # Misclassified or within margin\n",
    "            # Update weights and bias\n",
    "            for word in email:\n",
    "                if word in self.word2index:\n",
    "                    self.weights[self.word2index[word]] += self.alpha * (target - self.regularization_strength * self.weights[self.word2index[word]])\n",
    "            self.bias += self.alpha * target\n",
    "            return max(0, 1 - target * pred)  # Hinge loss\n",
    "        else:\n",
    "            # Regularization update (when the example is correctly classified)\n",
    "            for word in email:\n",
    "                if word in self.word2index:\n",
    "                    self.weights[self.word2index[word]] -= self.alpha * self.regularization_strength * self.weights[self.word2index[word]]\n",
    "            return 0\n",
    "\n",
    "# Train the SVM model\n",
    "model = SVM(spam[0:-1000], ham[0:-1000], iterations=20, alpha=0.008, regularization_strength=0.01)\n",
    "\n",
    "# Evaluate the model\n",
    "fp = 0\n",
    "tn = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, h in enumerate(ham[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred < 0:  # Negative class, so ham\n",
    "        tn += 1\n",
    "    else:  # False positive, classified as spam\n",
    "        fp += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * tn / float(tn + fp))[0:6])\n",
    "\n",
    "for i, h in enumerate(spam[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred > 0:  # Positive class, so spam\n",
    "        tp += 1\n",
    "    else:  # False negative, classified as ham\n",
    "        fn += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "print(\"\\n Accuracy: %\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "print(\"False Positives: %\" + str(100 * fp / float(tp + fp))[0:4] + \"    <- privacy violation level\")\n",
    "print(\"False Negatives: %\" + str(100 * fn / float(tn + fn))[0:4] + \"   <- security risk level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeaae1fe-e66e-4b55-bf9b-14201446380e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
