{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4e77389-55b0-452f-8938-5ddc357ed40f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extraction complete.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "def extract_emails(directory, output_file):\n",
    "    with open(output_file, 'w', encoding='utf-8') as out_file:\n",
    "        for root, _, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                # Process text files, eml files, or files without an extension\n",
    "                if file.endswith('.txt') or file.endswith('.eml') or not os.path.splitext(file)[1]:\n",
    "                    file_path = os.path.join(root, file)\n",
    "                    try:\n",
    "                        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:\n",
    "                            content = f.read()\n",
    "                            out_file.write(content + '\\n\\n')  # Separate emails by two newlines\n",
    "                    except Exception as e:\n",
    "                        print(f\"Error reading {file_path}: {e}\")\n",
    "\n",
    "# Paths to directories\n",
    "ham_dir = 'enron/ham'\n",
    "spam_dir = 'enron/spam'\n",
    "\n",
    "# Output files\n",
    "ham_output_file = 'enron/ham.txt'\n",
    "spam_output_file = 'enron/spam.txt'\n",
    "\n",
    "# Extract emails\n",
    "extract_emails(ham_dir, ham_output_file)\n",
    "extract_emails(spam_dir, spam_output_file)\n",
    "\n",
    "print(\"Extraction complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37114fdc-01f2-4e19-9cb0-ce66c1248ac8",
   "metadata": {},
   "source": [
    "## Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ebc58eb5-bbf3-45e7-8056-05bf266c62ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Importing dataset from disk...\n",
      "Iter:0 Loss:0.17723691243965922\n",
      "Iter:1 Loss:0.1518159145780536\n",
      "Iter:2 Loss:0.14444303680231094\n",
      "Iter:3 Loss:0.14093632480936893\n",
      "Iter:4 Loss:0.1384698558292573\n",
      "Iter:5 Loss:0.13689429473413126\n",
      "Iter:6 Loss:0.1357383294796565\n",
      "Iter:7 Loss:0.1347106069611384\n",
      "Iter:8 Loss:0.13406221429403853\n",
      "Iter:9 Loss:0.13371350537215843\n",
      " I:2000 % Correct:98.955\n",
      " Accuracy: %98.95\n",
      "False Positives: %1.77    <- privacy violation level\n",
      "False Negatives: %0.30   <- security risk level\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from collections import Counter\n",
    "import random\n",
    "import sys\n",
    "import chardet\n",
    "\n",
    "np.random.seed(12345)\n",
    "\n",
    "print(\"Importing dataset from disk...\")\n",
    "\n",
    "def detect_encoding(file_path):\n",
    "    with open(file_path, 'rb') as f:\n",
    "        raw_data = f.read()\n",
    "        result = chardet.detect(raw_data)\n",
    "        return result['encoding']\n",
    "\n",
    "# Detect encoding for spam.txt\n",
    "encoding_spam = detect_encoding('spam.txt')\n",
    "with open('spam.txt', 'r', encoding=encoding_spam, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "spam = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "# Detect encoding for ham.txt\n",
    "encoding_ham = detect_encoding('ham.txt')\n",
    "with open('ham.txt', 'r', encoding=encoding_ham, errors='replace') as f:\n",
    "    raw = f.readlines()\n",
    "\n",
    "ham = [row[:-2].split(\" \") for row in raw]\n",
    "\n",
    "class LogisticRegression(object):\n",
    "    \n",
    "    def __init__(self, positives, negatives, iterations=10, alpha=0.01, regularization_strength=0.01):\n",
    "        \n",
    "        self.maxweight = 10\n",
    "        self.alpha = alpha\n",
    "        self.regularization_strength = regularization_strength\n",
    "        \n",
    "        # Create vocabulary\n",
    "        cnts = Counter()\n",
    "        for email in (positives + negatives):\n",
    "            for word in email:\n",
    "                cnts[word] += 1\n",
    "        \n",
    "        vocab = list(cnts.keys())\n",
    "        self.word2index = {word: i for i, word in enumerate(vocab)}\n",
    "    \n",
    "        # Initialize weights\n",
    "        self.weights = (np.random.rand(len(vocab)) - 0.5) * 0.1\n",
    "        \n",
    "        # Train model\n",
    "        self.train(positives, negatives, iterations=iterations)\n",
    "    \n",
    "    def train(self, positives, negatives, iterations=10):\n",
    "        \n",
    "        for iter in range(iterations):\n",
    "            error = 0\n",
    "            n = 0\n",
    "            for i in range(max(len(positives), len(negatives))):\n",
    "                error += np.abs(self.learn(positives[i % len(positives)], 1))\n",
    "                error += np.abs(self.learn(negatives[i % len(negatives)], 0))\n",
    "                n += 2\n",
    "\n",
    "            print(\"Iter:\" + str(iter) + \" Loss:\" + str(error / float(n)))\n",
    "    \n",
    "    @staticmethod\n",
    "    def softmax(x):\n",
    "        x = np.clip(x, -500, 500)  # Clip values to avoid overflow\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def predict(self, email):\n",
    "        return self.unencrypted_predict(email)\n",
    "    \n",
    "    def unencrypted_predict(self, email):\n",
    "        pred = 0\n",
    "        for word in email:\n",
    "            pred += self.weights[self.word2index[word]]\n",
    "        pred = self.softmax(pred)\n",
    "        return pred\n",
    "\n",
    "    def learn(self, email, target):\n",
    "        pred = self.predict(email)\n",
    "        delta = (pred - target)\n",
    "        for word in email:\n",
    "            self.weights[self.word2index[word]] -= (delta * self.alpha + self.regularization_strength * self.weights[self.word2index[word]])\n",
    "        return delta\n",
    "\n",
    "model = LogisticRegression(spam[0:-5000], ham[0:-5000], iterations=10, alpha=0.01, regularization_strength=0.01)\n",
    "\n",
    "# Evaluate the model\n",
    "fp = 0\n",
    "tn = 0\n",
    "tp = 0\n",
    "fn = 0\n",
    "\n",
    "for i, h in enumerate(ham[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred < 0.5:\n",
    "        tn += 1\n",
    "    else:\n",
    "        fp += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * tn / float(tn + fp))[0:6])\n",
    "\n",
    "for i, h in enumerate(spam[-1000:]):\n",
    "    pred = model.predict(h)\n",
    "    if pred > 0.5:\n",
    "        tp += 1\n",
    "    else:\n",
    "        fn += 1\n",
    "\n",
    "    if i % 10 == 0:\n",
    "        sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "sys.stdout.write('\\r I:' + str(tn + tp + fn + fp) + \" % Correct:\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "\n",
    "print(\"\\n Accuracy: %\" + str(100 * (tn + tp) / float(tn + tp + fn + fp))[0:6])\n",
    "print(\"False Positives: %\" + str(100 * fp / float(tp + fp))[0:4] + \"    <- privacy violation level\")\n",
    "print(\"False Negatives: %\" + str(100 * fn / float(tn + fn))[0:4] + \"   <- security risk level\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "069383a7-ff88-4e9e-88b4-fd2686c6830c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:12345\n",
      "\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "127.0.0.1 - - [16/Sep/2024 10:53:56] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:53:56] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:08] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:08] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:11] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:12] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:54:57] \"\u001b[31m\u001b[1mPOST /predict HTTP/1.1\u001b[0m\" 400 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:55:02] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:55:33] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 10:56:00] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 11:03:52] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 11:03:52] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 11:21:23] \"POST /predict HTTP/1.1\" 200 -\n",
      "127.0.0.1 - - [16/Sep/2024 11:21:40] \"POST /predict HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "## from flask import Flask, request, jsonify\n",
    "import re\n",
    "\n",
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "\n",
    "# Assuming `model` is your unencrypted model from previous steps\n",
    "# Initialize the model here if necessary\n",
    "\n",
    "# Define the preprocessing function to handle case and punctuation\n",
    "def preprocess_email(email):\n",
    "    # Convert to lowercase\n",
    "    email = email.lower()\n",
    "    \n",
    "    # Remove punctuation using regex\n",
    "    email = re.sub(r'[^\\w\\s]', '', email)\n",
    "    \n",
    "    # Tokenize by splitting on spaces\n",
    "    email_tokens = email.split()\n",
    "    \n",
    "    return email_tokens\n",
    "\n",
    "@app.route('/predict', methods=['POST'])\n",
    "def predict():\n",
    "    data = request.json\n",
    "    email = data.get('email', '')\n",
    "    \n",
    "    if not email:\n",
    "        return jsonify({'error': 'No email provided'}), 400\n",
    "    \n",
    "    # Preprocess the email input\n",
    "    email_tokens = preprocess_email(email)\n",
    "    \n",
    "    # Run through the model\n",
    "    try:\n",
    "        pred = model.predict(email_tokens)\n",
    "        \n",
    "        # Determine whether it's spam or not\n",
    "        if pred > 0.5:\n",
    "            result = \"spam\"\n",
    "        else:\n",
    "            result = \"not spam\"\n",
    "        \n",
    "        # Return the result as JSON\n",
    "        return jsonify({'prediction': result})\n",
    "    \n",
    "    except KeyError as e:\n",
    "        # Return an error message if a word is not found in the vocabulary\n",
    "        return jsonify({'error': f\"Word '{e.args[0]}' not in vocabulary\"}), 400\n",
    "\n",
    "# Run the Flask server\n",
    "if __name__ == '__main__':\n",
    "    app.run(port=12345)  # Default port is 5000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c8b887e-4f96-4478-ad30-30851104e333",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating paillier keypair\n"
     ]
    }
   ],
   "source": [
    "import phe as paillier\n",
    "print (\"Generating paillier keypair\")\n",
    "pubkey, prikey = paillier.generate_paillier_keypair(n_length=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "584fcec9-5bd7-4f56-b014-679a2852d25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = pubkey.encrypt (123)\n",
    "b= pubkey.encrypt (-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4ba24d18-dd97-4494-8e74-4e10a2176fe6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "123"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prikey.decrypt(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "769da172-c758-42d6-ae3f-b096ec58a055",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<phe.paillier.EncryptedNumber object at 0x10f275760>\n",
      "<phe.paillier.EncryptedNumber object at 0x10f0df290>\n"
     ]
    }
   ],
   "source": [
    "print(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d89d6ff7-c033-414f-b6bc-f7fe1418d9ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prikey.decrypt(a+a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "12d62489-f054-477d-8f3a-526bfba148d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "c=a+a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aae67ec6-7680-4257-8de2-866efc84281b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<phe.paillier.EncryptedNumber object at 0x10f307e60>\n"
     ]
    }
   ],
   "source": [
    "print(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c9421577-655f-4174-b388-901001ca1bd2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "246"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prikey.decrypt(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cecd7267-c86e-4e28-bfe8-80eee0112d28",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original messages: 42, 23\n",
      "Encrypted messages: <EncryptedNumber object at 0x10f0df980>, <EncryptedNumber object at 0x10f261b50>\n",
      "Encrypted sum: <EncryptedNumber object at 0x10aefb620>\n",
      "Decrypted sum: 65\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "import libnum\n",
    "\n",
    "# Function to compute modular inverse\n",
    "def mod_inverse(x, n):\n",
    "    return pow(x, -1, n)\n",
    "\n",
    "# L function for decryption\n",
    "def L(x, n):\n",
    "    return (x - 1) // n\n",
    "\n",
    "# Paillier key generation using libnum for prime generation\n",
    "def generate_keys(bit_length=512):\n",
    "    # Generate two large prime numbers p and q using libnum\n",
    "    p = libnum.generate_prime(bit_length // 2)\n",
    "    q = libnum.generate_prime(bit_length // 2)\n",
    "\n",
    "    n = p * q  # n = p * q\n",
    "    n_sq = n * n  # n^2 for the modulus in encryption\n",
    "\n",
    "    # λ (lambda) = lcm(p-1, q-1)\n",
    "    lambda_param = (p - 1) * (q - 1) // math.gcd(p - 1, q - 1)\n",
    "\n",
    "    # g can be any number (usually n+1)\n",
    "    g = n + 1\n",
    "\n",
    "    # µ = (L(g^λ mod n^2))^(-1) mod n\n",
    "    mu = mod_inverse(L(pow(g, lambda_param, n_sq), n), n)\n",
    "\n",
    "    public_key = (n, g)\n",
    "    private_key = (lambda_param, mu)\n",
    "\n",
    "    return public_key, private_key\n",
    "\n",
    "# Custom EncryptedNumber class to mimic object-like string representation\n",
    "class EncryptedNumber:\n",
    "    def __init__(self, ciphertext):\n",
    "        self.ciphertext = ciphertext\n",
    "\n",
    "    def __str__(self):\n",
    "        # This returns a string similar to an object representation\n",
    "        return f\"<EncryptedNumber object at {hex(id(self))}>\"\n",
    "\n",
    "# Paillier encryption\n",
    "def encrypt(public_key, plaintext):\n",
    "    n, g = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Choose random r where 1 <= r < n\n",
    "    r = libnum.randint_bits(n.bit_length() - 1) % n\n",
    "\n",
    "    # Encryption formula: c = g^m * r^n mod n^2\n",
    "    ciphertext = (pow(g, plaintext, n_sq) * pow(r, n, n_sq)) % n_sq\n",
    "    return EncryptedNumber(ciphertext)  # Wrap ciphertext in EncryptedNumber class\n",
    "\n",
    "# Paillier decryption\n",
    "def decrypt(private_key, public_key, encrypted_number):\n",
    "    n, g = public_key\n",
    "    lambda_param, mu = private_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Extract the actual ciphertext from the EncryptedNumber object\n",
    "    ciphertext = encrypted_number.ciphertext\n",
    "\n",
    "    # Decryption formula: m = L(c^λ mod n^2) * µ mod n\n",
    "    x = pow(ciphertext, lambda_param, n_sq)\n",
    "    plaintext = (L(x, n) * mu) % n\n",
    "    return plaintext\n",
    "\n",
    "# Homomorphic addition of two ciphertexts\n",
    "def homomorphic_add(public_key, c1, c2):\n",
    "    n, _ = public_key\n",
    "    n_sq = n * n\n",
    "\n",
    "    # Homomorphic addition: c3 = (c1 * c2) mod n^2\n",
    "    return EncryptedNumber((c1.ciphertext * c2.ciphertext) % n_sq)\n",
    "\n",
    "# Example usage:\n",
    "if __name__ == \"__main__\":\n",
    "    # Key generation (512-bit security)\n",
    "    public_key, private_key = generate_keys(bit_length=512)\n",
    "\n",
    "    # Encrypt two messages\n",
    "    m1 = 42\n",
    "    m2 = 23\n",
    "    print(f\"Original messages: {m1}, {m2}\")\n",
    "\n",
    "    c1 = encrypt(public_key, m1)\n",
    "    c2 = encrypt(public_key, m2)\n",
    "    print(f\"Encrypted messages: {c1}, {c2}\")\n",
    "\n",
    "    # Homomorphic addition of encrypted messages\n",
    "    c3 = homomorphic_add(public_key, c1, c2)\n",
    "    print(f\"Encrypted sum: {c3}\")\n",
    "\n",
    "    # Decrypt the sum\n",
    "    decrypted_sum = decrypt(private_key, public_key, c3)\n",
    "    print(f\"Decrypted sum: {decrypted_sum}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9eb90b39-bfca-4b82-85f4-f7b241183108",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting libnum\n",
      "  Downloading libnum-1.7.1-py3-none-any.whl.metadata (4.6 kB)\n",
      "Downloading libnum-1.7.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: libnum\n",
      "Successfully installed libnum-1.7.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install libnum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4d83680-c476-4070-94b2-6a48bcc1390d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
